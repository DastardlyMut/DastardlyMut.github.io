#
# Be aware that even a small syntax error here can lead to failures in output.
#

sidebar:
    about: False # set to False or comment line if you want to remove the "how to use?" in the sidebar
    education: True # set to False if you want education in main section instead of in sidebar
    interests: True 
    # Profile information
    name: Sean Devonport
    tagline: Audio Engineering | Programming | Sound Design
    avatar: profile.png  #place a 100x100 picture inside /assets/images/ folder and provide the name of the file below
    # Sidebar links
    email: tonetechnician@gmail.com
    phone: +2783 675 3997
    # website: blog.webjeda.com #do not add http://
    linkedin: sean-devonport-316b7a121
    linkedin-name: sean-devonport
    github: tonetechnician
    gitlab: tonetechnician
    bitbucket:
    twitter: 

    soundcloud: tone_tastic
    soundcloud-name: tone.tastic
    codewars:
    goodreads: # Number-Username, e.g. 123456-alandoe

    languages:
      - idiom: English
        level: Native

    interests:
      - item: Skateboarding
        link:

      - item: Immersive Arts
        link:

career-profile:
    title: Profile
    summary: |
      I am a dedicated software developer and always eager to learn. I love meeting and working with new people as well as engaging with new and interesting technologies. 
      My expertise is in audio software development, XMOS firmware programming, control systems development, sound engineering and sound design. I've also been lead tech and rigger for multiple immersive media and multi-speaker environments.
      More recently I've become very interested in immersive support therapy, immersive media for conservation and immersive media for space exploration. There is a wealth of knowledge to be uncovered.
      If I'm not thinking about this, I'm most likely in the outdoors recording 360 audio ambience, skateboarding or flying my drone around. 

education:
    - degree: MSc in Computer Science with Distinction
      university: Rhodes University, South Africa
      time: 2017 - 2018
      details: |
        thesis-title: An Investigation into the Application of Distributed Endpoint Processing to 3D Immersive Audio Rendering

    - degree: BSc with Honours in Computer Science and Pure Mathematics
      university: Rhodes University, South Africa
      time: 2012 - 2016
      details: |
        Minor subjects in
          - Sound Technology
          - Musicology
          - Electronics

    - degree: South African National Senior Certificate with Independent Examination Boards (IEB)
      university: St Johns College
      time: 2011
      details: |
        Distinctions in 
          - Mathematics
          - Geography

experiences:
    - role: Software and Embedded Systems Engineer
      time: 2016 - present
      company: ImmersiveDSP startup in collaboration with MiniDSP
      details: |
        This role has me involved with development of the core immerGo system. Specifically,
          - Frontend development for mobile device interface and browsers using ECMAScript, HTML5, CSS and Cordova
          - NodeJS server development with NWJS
          - Immersive audio speaker rendering algorithms (DBAP, VBAP, Ambisonics, Wave Field Synthesis)
          - Hybridization of immersive audio rendering algorithms 
          - Software license manager for immersiveDSP products.
          - XMOS xC firmware development on top of the AVB stack
          - C++ application development using the JUCE framework
          - Unity + Wwise integrations for immerGo-VR software
          - MaxMSP development rolled out to standalone software
          - Ethernet AVB audio networks automated network configuration and management
          - DevOps pipelines to automate build and delivery of software products and hardware firmware
          - Product promotion
          - Product educational workshops
          - Spatial Audio Content creation
          - Research in as much cutting edge audio and speaker technology as possible

    - role: Freelance software engineer and systems integrator
      time: 2017 - present
      company: Freelance
      details: |
        I'm a freelance software engineer and systems integrator mostly focused in programming to provide tools and system architectures to achieve artist's visions. This has had me work with many different people and companies from all over the world. 

    - role: Audio/Visual Technician and Sound Engineer
      time: 2014 - present
      company: Freelance
      details: |
        I have been lead audio technician working on a variety of mixed media, immersive audio installation projects. Particular projects are listed in the section below.

    - role: Co-founder
      time: 2017 - present
      company: Skate Ubuntu
      details: |
        I am a founding member of the non-profit organization Skate Ubuntu that is actively working with the local under-privileged Grahamstown community.
        This has had me involved with 
          - fundraising
          - crowdfunding 
          - event management 
          - hands-on skateboard tutoring
          - organizational responsibilities that involve leadership, public promotions and social upliftment

projects:
    title: Projects
    intro: >
      This is a list of my most recent endeavours in mixed-media programming, control system engineering, software development, audio for virtual reality and recording and sound engineering. 
    productions:
      - title: UAE2020 World Expo (2020 - 2021)
        link: https://www.expo2020dubai.com/ 
        tagline: Software Engineer, VR spatial audio developer, systems integrator, recording engineer and specialist audio programmer.
        info: I have been subcontracted as a specialist audio programmer working in a variety of aspects for both installed and VR sound for the UAE2020 World Expo. This project has had me build and work with a variety of different hardware and software. I've needed to hack Brightsign players, create generative style playback in the Q-Sys Qcore ecosystem with Lua scripting, build tools in Unreal to aid the mixing in realtime VR audio simulations, manage recording devices and help manage an integration team. 
        
      - title: OhGod in Immersive Sound (2019)
        link: https://www.quicket.co.za/events/93138-immersivedsp-presents-ohgod-live-in-immersive-surround-sound/
        tagline: Lead audio tech engineer 
        info: This was ImmersiveDSP's first step into immersive sound for live performance. The system I built for this event allowed for the playback ambisonic recordings, triggered surround sound and non-surround audio stems, object based control over these triggered samples and live instrument signals and my own custom designed spatial audio fx created using object based audio techniques. The beauty of this system is that in realtime, it also records the audio object positions and signals into an Ambisonic 2nd order format on a seperate computer. This allows for clean audio signal and spatializated audio to be recorded and then spliced with the 360 footage that was captured at the event. The hopes that this sort of system can be incorporated easily into live sound, and also provide the option to record the entire performance with spatial fidelity for further distribution and publicity of the event.

      - title: The Earth Space Program (2019)
        link: https://www.playtopia.co.za/
        tagline: Control systems and sound engineer 
        info: Interactive lighting and audio/visual immersive installation using analog equipment (a turntable) and realtime digital audio over Ethernet AVB. This work included a 12.1 channel soundsystem housed in a gazebo. A turntable was at the centre of the gazebo which was used to control the triggering of various ambisonic recordings and spatial audio FX according to various states that the system could be put in. A Microsoft Kinect was included to control reactive LED lighting, and trigger particular recordings according to the positions of users in the space. Three LED strips were connected to two different Arduinos that were connected to the host computer over USB serial which provided an interface for the Kinect to control the lighting. 

      - title: Tectonik Tombwa (2019)
        link: https://prohelvetia.org.za/en/2019/04/23/vela-6911-tectoniktombwa-by-victor-gama-and-stacy-hardy/
        tagline: Sound and recording engineer 
        info: Live instrumental mixing with video projection Victor Gama

      - title: Exploitation! (2018)
        link: http://africanah.org/heidi-sincuba-2/ 
        tagline: Lead audio/visual tech
        info: Managed the production of both audio and visual content for fine artist Heidi Sincuba’s art installation, entitled ‘Exploitation’. This took place at the 2018 National Arts Festival. My involvement included work for the pre- to post-production of the digital media, as well as installing the exhibition’s 18 channel sound system and visual projection. This work made use of the ImmerGO sound system which I have been involved in developing with miniDSP.

      - title: Input Lag (2018)
        link: https://www.facebook.com/pages/category/Visual-Arts/Input-Lag-2193186604330071/
        tagline: Audio engineering for artist Justin Share's art graduate final piece
        info: Built the automated control system that was fed input data from facebook graph api. This data was then used to control Resolume, Ableton and a printer. The concept had users interacting with a facebook live stream of the exhibition space. These would then trigger various controls that would affect the live stream video and a Louville laser within the space.
      
      - title: Down to a Sunless Sea - Standard Bank Ovation award winning immersive installation with Lexi Meier (2017)
        link: https://leximeierchoreography.wordpress.com/2017/07/27/down-to-a-sunless-sea/
        tagline: Lead audio tech
        info: Co-created the sound score, setup the 24 speaker system and performed the live mix for ‘Down to a Sunless Sea’ . This work made use of the ImmerGO sound system which I have been involved in developing with miniDSP.

      - title: Fabric of the Universe - Standard Bank Ovation award winning immersive installation with Lexi Meier (2016)
        link: https://leximeierchoreography.wordpress.com/2017/07/27/fabric-of-the-universe-2016/
        tagline: Lead audio tech
        info: Co-created the sound score, setup the 24 speaker system and performed a live mix of the score for ‘Fabric of the Universe’. This work made use of the ImmerGO sound system which I have been involved in developing with miniDSP.

    assignments:
      - title: facebook-music-maker
        link: "https://github.com/tonetechnician/facebook-music-maker"
        tagline: A nodeJS  server that interacts with the facebook graph api to create MIDI sequences and print to a printer
        info: This was used in a mixed media final art graduate exhibition. The server was hooked up to control both resolume and Ableton Live.
        
      - title: teleMax
        link: "https://github.com/tonetechnician/teleMax"
        tagline: MaxMSP project for the sonification of network telescope data
        info: This is the MaxMSP patch that sonified network telescope data according to output from a python script. It was the project presented at BSides Cape Town, 2018.

publications:
    title: Publications
    intro: |
      The publications below include my masters thesis and peer-reviewed papers that I have contributed to

    thesis:
      - title: "An Investigation into the Application of Distributed Endpoint Processing to 3D Immersive Audio Rendering"
      - abstract: 3D immersive audio rendering systems use algorithms that accurately render the perceived location of an audio source within a space using multiple sets of loudspeakers. The algorithms used by these renderers can become very processor intensive as the number of tracks and loudspeakers being used increases. The ImmerGo spatial audio system provides a solution to this by using distributed endpoint processing. Immergo uses a client-server architecture that control multiple smaller endpoints distributed on an Ethernet Audio Video Bridging (AVB) network. Each endpoint contains an audio mixer which is dedicated to mixing audio to a smaller subset of speakers according to commands from ImmerGo.
                  The ImmerGo system performs its rendering calculations within the host computer and then mixes the audio at each endpoint. The work in this thesis identified that the processing load put on the host computer due to these calculations may be mitigated by offloading the rendering algorithm calculations to the endpoints as well. In order to prove this for a number of different algorithms, the ImmerGo system was modified to include three new algorithms as well as the one it currently uses. Each algorithm then had its processing offloaded to the endpoints at three successive steps of distribution. Tests were performed to determine the limitations of each step, and how the host processor and endpoint processors were affected by distributing the calculations. Listening tests were also performed to ensure that each newly introduced algorithm was implemented correctly.  

    papers:
      - title: "The Distribution of Ambisonic and Point Source Rendering to Ethernet AVB Speakers"
        authors: Sean Devonport & Richard Foss
        conference: International Conference on Spatial Audio, Ilmenau, Germany, 2019

      - title: "An Investigation into the Distribution of 3D Immersive Audio Renderer Processing to Speaker Endpoint Processors"
        authors: Sean Devonport & Richard Foss
        conference: 30th Tonmeistertagung VDT, Cologne, Germany, 2018

      - title: "An Immersive Audio Control System Using Mobile Devices and Ethernet AVB-Capable Speakers"
        authors: Sean Devonport & Richard Foss
        conference: "Journal Audio Engineering Society (JAES) Vol. 66 no. 9 pp724-733, 2018"

      - title: "An Investigation into the Application of Distributed Endpoint Processing to 3D Immersive Audio Reproduction"
        authors: Sean Devonport & Richard Foss
        conference: "Southern Africa Telecommunication Networks and Applications Conference (SATNAC), Hermanus, 2018"

      - title: "Hearing the Internet Background Radiation"
        authors: Sean Devonport & Brent Shaw
        conference: "Bsides, Cape Town, 2018"

skills:
    title: Skills &amp; Proficiency

    toolset:
      - name: Javascript (ECMAScript)
      - name: NodeJS including native C++ addons with node-gyp and cmake bindings
      - name: HTML5 & CSS 
      - name: XMOS and xC embedded software development
      - name: Audio DSP concepts – filtering, delay buffers, smoothing, convolution etc..
      - name: Ethernet AVB and Audio Networking
      - name: git + gitHub + gitLab
      - name: Remote project management with tools like Trello
      - name: Acoustics and psychoacoustics in context with loudspeakers and spatial audio
      - name: MaxMSP
      - name: C++
      - name: JUCE framework
      - name: Matlab/Octave
      - name: Python (research projects)
      - name: Experience with Ionic (no product pushed to production)
      - name: Experience with AngularJS (no product pushed to production)
      - name: Experience with React (no product pushed to production)

# footer: >
#     Designed with <i class="fas fa-heart"></i> by <a href="http://themes.3rdwavemedia.com" target="_blank" rel="nofollow">Xiaoying Riley</a>
